# distributed setting
distributed: False

# amp parameters
apex_amp: False
native_amp: False

# model parameters
model: swin_base_patch4_window7_224
num_classes: 1000
create_model_pretrained: True
pretrain: './outputs/gradnorm_swinb_variant/2024-02-14_11-30-41/last.pth.tar'
gp: null
channels_last: False

# Batch norm parameters
bn_momentum: null
bn_eps: null
sync_bn: False
dist_bn: reduce
split_bn: False

# optimizer parameters
opt: adamw
opt_eps: 1.0e-8
opt_betas: null
momentum: 0.9
weight_decay: 0.05
clip_grad: 1.0
clip_mode: norm
layer_decay: null

# lr schedule
epochs: 30 #5
sched: cosine
lrb: 2.5e-5
lr: null
lr_noise: null
lr_noise_pct: 0.67
lr_noise_std: 1.0
lr_cycle_mul: 1.0
lr_cycle_decay: 0.5
lr_cycle_limit: 1
lr_k_decay: 1.0
warmup_lr: 1.0e-5
min_lr: 1.0e-5
epoch_repeats: 0
start_epoch: null
decay_epochs: 9 #3
warmup_epochs: 5 #2
cooldown_epochs: 0
patience_epochs: 0
decay_rate: 0.1

# dataset parameters
batch_size: 38
grad_accum: 2
train_dir: /data/vision/torralba/datasets/imagenet_pytorch/ImageNet/train
eval_dir: /data/vision/torralba/datasets/imagenet_pytorch/ImageNet/val
input_size: 224
crop_pct: 0.875
interpolation: bicubic
mean: [0.485, 0.456, 0.406]
std: [0.229, 0.224, 0.225]

# augmentation
no_aug: False
color_jitter: 0.4
aa: rand-m9-mstd0.5-inc1
aug_repeats: 0
aug_splits: 0
jsd_loss: False
# random erase
reprob: 0.25
remode: pixel
recount: 1
resplit: False
mixup: 0.8
cutmix: 1.0
cutmix_minmax: null
mixup_prob: 1.0
mixup_switch_prob: 0.5
mixup_mode: batch
mixup_off_epoch: 0
smoothing: 0.1
train_interpolation: bicubic
# drop connection
drop: 0.0
drop_path: 0.0
drop_block: null

# ema
model_ema: True
model_ema_force_cpu: False
model_ema_decay: 0.9998

# misc
seed: 0
log_interval: 50
recovery_interval: 0
max_history: 5
num_workers: 6
output_dir: 'arxiv_outputs/gradnorm_swinb_finetuning_pareto_08'
save_log: save_log.txt
eval_metric: advtop1
pin_mem: True

# advtrain
advtrain: False
attack_criterion: mixup

# gradnorm
gradnorm: True
loss_fn: 'DBP'
ce_weight: 1.2
gradnorm_weight: 0.8
alpha: [1.0, 0.0, 1.0]
alpha_start_epoch: 0

# saving snapshots
save_snapshot_for_inference: ['10;-1', '20;-1']
collect_gradient_statistics: [0,1]